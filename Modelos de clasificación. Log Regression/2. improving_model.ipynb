{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (821, 7)\n",
      "Test shape:  (274, 7)\n",
      "     avalanche  no_visitors  surface_hoar  fresh_thickness  wind  weak_layers  \\\n",
      "176          0            9      5.142447         9.877195     6            8   \n",
      "114          1            3      8.170281         9.136835    34            7   \n",
      "869          0            3      1.979579         9.497017    10            8   \n",
      "775          1            0      1.999078         9.337908    21            6   \n",
      "181          1            9      6.854401         6.099359    22            5   \n",
      "\n",
      "     tracked_out  \n",
      "176            1  \n",
      "114            0  \n",
      "869            0  \n",
      "775            0  \n",
      "181            0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('avalanche.csv', delimiter='\\t', index_col=0)\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.25, random_state=10)\n",
    "\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `surface_hoar` is how disturbed the surface of the snow is\n",
    "\n",
    "- `fresh_thickness` is how thick the top layer of snow is, or 0 if there's no fresh snow on top\n",
    "\n",
    "- `wind` is the top wind speed that day, in km/h\n",
    "\n",
    "- `weak_layers` is the number of layers of snow that aren't well-bound to other layers\n",
    "\n",
    "- `no_visitors` is the number of hikers who were on the trail that day\n",
    "\n",
    "- `tracked_out` is a 1 or 0. A 1 means that the snow has been trampled heavily by hikers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616312\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.logit('avalanche ~ weak_layers', train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model):\n",
    "    # Make estimations and convert to categories\n",
    "    avalance_predicted = model.predict(test) > 0.5\n",
    "\n",
    "    # Calculate accuracy\n",
    "    print('Accuracy: ', accuracy_score(test['avalanche'], avalance_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6167883211678832\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.459347\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "# Improving the model by adding more variables\n",
    "model_all_features = smf.logit('avalanche ~ weak_layers + wind + surface_hoar + fresh_thickness + no_visitors + tracked_out', train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7846715328467153\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(model_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   821</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.3305</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:20:03</td>     <th>  Log-Likelihood:    </th> <td> -377.12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -563.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.372e-77</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -4.0107</td> <td>    0.443</td> <td>   -9.043</td> <td> 0.000</td> <td>   -4.880</td> <td>   -3.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>     <td>    0.3733</td> <td>    0.034</td> <td>   10.871</td> <td> 0.000</td> <td>    0.306</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>            <td>    0.1009</td> <td>    0.009</td> <td>   11.149</td> <td> 0.000</td> <td>    0.083</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>    <td>    0.3306</td> <td>    0.035</td> <td>    9.424</td> <td> 0.000</td> <td>    0.262</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th> <td>   -0.0220</td> <td>    0.030</td> <td>   -0.732</td> <td> 0.464</td> <td>   -0.081</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>     <td>   -0.1060</td> <td>    0.032</td> <td>   -3.262</td> <td> 0.001</td> <td>   -0.170</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tracked_out</th>     <td>   -0.0664</td> <td>    0.181</td> <td>   -0.367</td> <td> 0.713</td> <td>   -0.420</td> <td>    0.288</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  821\n",
       "Model:                          Logit   Df Residuals:                      814\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Mon, 20 Mar 2023   Pseudo R-squ.:                  0.3305\n",
       "Time:                        11:20:03   Log-Likelihood:                -377.12\n",
       "converged:                       True   LL-Null:                       -563.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.372e-77\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -4.0107      0.443     -9.043      0.000      -4.880      -3.141\n",
       "weak_layers         0.3733      0.034     10.871      0.000       0.306       0.441\n",
       "wind                0.1009      0.009     11.149      0.000       0.083       0.119\n",
       "surface_hoar        0.3306      0.035      9.424      0.000       0.262       0.399\n",
       "fresh_thickness    -0.0220      0.030     -0.732      0.464      -0.081       0.037\n",
       "no_visitors        -0.1060      0.032     -3.262      0.001      -0.170      -0.042\n",
       "tracked_out        -0.0664      0.181     -0.367      0.713      -0.420       0.288\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the P column, recalling that values less than 0.05 mean we can be confident that this parameter is helping the model make better predictions.\n",
    "\n",
    "Both surface_hoar and wind have very small values here, meaning they're useful predictors and probably explain why our model is working better. If we look at the coef (which states parameters) column we see that these have positive values. This means that higher winds, and greater amounts of surface hoar result in higher avalanche risk.\n",
    "\n",
    "### Simplifying our model\n",
    "\n",
    "Looking at the summary again, we can see that tracked_out (how trampled the snow is), and fresh_thickness have large p-values. This means they aren't useful predictors. Let's see what happens if we remove them from our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.459760\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "model_simplified = smf.logit('avalanche ~ weak_layers + wind + surface_hoar + no_visitors', train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.781021897810219\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   821</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   816</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.3299</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:27:04</td>     <th>  Log-Likelihood:    </th> <td> -377.46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -563.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.552e-79</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   -4.2191</td> <td>    0.366</td> <td>  -11.535</td> <td> 0.000</td> <td>   -4.936</td> <td>   -3.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>  <td>    0.3738</td> <td>    0.034</td> <td>   10.882</td> <td> 0.000</td> <td>    0.306</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>         <td>    0.1007</td> <td>    0.009</td> <td>   11.166</td> <td> 0.000</td> <td>    0.083</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th> <td>    0.3303</td> <td>    0.035</td> <td>    9.423</td> <td> 0.000</td> <td>    0.262</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>  <td>   -0.1053</td> <td>    0.032</td> <td>   -3.249</td> <td> 0.001</td> <td>   -0.169</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  821\n",
       "Model:                          Logit   Df Residuals:                      816\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Mon, 20 Mar 2023   Pseudo R-squ.:                  0.3299\n",
       "Time:                        11:27:04   Log-Likelihood:                -377.46\n",
       "converged:                       True   LL-Null:                       -563.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 3.552e-79\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       -4.2191      0.366    -11.535      0.000      -4.936      -3.502\n",
       "weak_layers      0.3738      0.034     10.882      0.000       0.306       0.441\n",
       "wind             0.1007      0.009     11.166      0.000       0.083       0.118\n",
       "surface_hoar     0.3303      0.035      9.423      0.000       0.262       0.399\n",
       "no_visitors     -0.1053      0.032     -3.249      0.001      -0.169      -0.042\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simplified.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   821</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.3305</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:28:14</td>     <th>  Log-Likelihood:    </th> <td> -377.12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -563.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.372e-77</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -4.0107</td> <td>    0.443</td> <td>   -9.043</td> <td> 0.000</td> <td>   -4.880</td> <td>   -3.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>     <td>    0.3733</td> <td>    0.034</td> <td>   10.871</td> <td> 0.000</td> <td>    0.306</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>            <td>    0.1009</td> <td>    0.009</td> <td>   11.149</td> <td> 0.000</td> <td>    0.083</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>    <td>    0.3306</td> <td>    0.035</td> <td>    9.424</td> <td> 0.000</td> <td>    0.262</td> <td>    0.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th> <td>   -0.0220</td> <td>    0.030</td> <td>   -0.732</td> <td> 0.464</td> <td>   -0.081</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>     <td>   -0.1060</td> <td>    0.032</td> <td>   -3.262</td> <td> 0.001</td> <td>   -0.170</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tracked_out</th>     <td>   -0.0664</td> <td>    0.181</td> <td>   -0.367</td> <td> 0.713</td> <td>   -0.420</td> <td>    0.288</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  821\n",
       "Model:                          Logit   Df Residuals:                      814\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Mon, 20 Mar 2023   Pseudo R-squ.:                  0.3305\n",
       "Time:                        11:28:14   Log-Likelihood:                -377.12\n",
       "converged:                       True   LL-Null:                       -563.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.372e-77\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -4.0107      0.443     -9.043      0.000      -4.880      -3.141\n",
       "weak_layers         0.3733      0.034     10.871      0.000       0.306       0.441\n",
       "wind                0.1009      0.009     11.149      0.000       0.083       0.119\n",
       "surface_hoar        0.3306      0.035      9.424      0.000       0.262       0.399\n",
       "fresh_thickness    -0.0220      0.030     -0.732      0.464      -0.081       0.037\n",
       "no_visitors        -0.1060      0.032     -3.262      0.001      -0.170      -0.042\n",
       "tracked_out        -0.0664      0.181     -0.367      0.713      -0.420       0.288\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our new model works very similarly to the old one! In some circumstances simplifying a model like this can even improve it, as it becomes less likely to overfit.\n",
    "\n",
    "### Careful feature selection\n",
    "\n",
    "Usually, we don't just pick features blindly. Let's think about what we've just done - we removed how much fresh snow was in a model, trying to predict avalanches. Something seems off. Surely avalanches are much more likely after it has snowed? Similarly, the number of people on the track seems unrelated to how many avalanches there were, but we know that people often can trigger avalanches.\n",
    "\n",
    "Look at the `fresh_thickness` row. We're told that it has a negative coefficient. This means that as thickness increases, avalanches decrease.\n",
    "\n",
    "Similarly, `no_visitors` has a negative coefficient, meaning that fewer hikers means more avalanches.\n",
    "\n",
    "How can this bes? Well, while visitors can cause avalanches if there's a lot of fresh snow, presumably they cannot do so easily if there's no fresh snow. This means that our features aren't fully independent.\n",
    "\n",
    "We can tell the model to try to take into account that these features interact, using a multiply sign. Let's try that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413538\n",
      "         Iterations 7\n",
      "Accuracy:  0.8357664233576643\n"
     ]
    }
   ],
   "source": [
    "formula = 'avalanche ~ weak_layers + surface_hoar + wind + no_visitors * fresh_thickness'\n",
    "model_with_interaction = smf.logit(formula, train).fit()\n",
    "calculate_accuracy(model_with_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   821</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 20 Mar 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.3973</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>11:32:32</td>     <th>  Log-Likelihood:    </th> <td> -339.51</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -563.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.587e-93</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>   -0.9606</td> <td>    0.587</td> <td>   -1.636</td> <td> 0.102</td> <td>   -2.111</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>                 <td>    0.4327</td> <td>    0.039</td> <td>   11.193</td> <td> 0.000</td> <td>    0.357</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>                <td>    0.3887</td> <td>    0.039</td> <td>   10.035</td> <td> 0.000</td> <td>    0.313</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>                        <td>    0.1204</td> <td>    0.010</td> <td>   11.607</td> <td> 0.000</td> <td>    0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>                 <td>   -0.9430</td> <td>    0.114</td> <td>   -8.237</td> <td> 0.000</td> <td>   -1.167</td> <td>   -0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th>             <td>   -0.4962</td> <td>    0.069</td> <td>   -7.191</td> <td> 0.000</td> <td>   -0.631</td> <td>   -0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors:fresh_thickness</th> <td>    0.1015</td> <td>    0.013</td> <td>    7.835</td> <td> 0.000</td> <td>    0.076</td> <td>    0.127</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  821\n",
       "Model:                          Logit   Df Residuals:                      814\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Mon, 20 Mar 2023   Pseudo R-squ.:                  0.3973\n",
       "Time:                        11:32:32   Log-Likelihood:                -339.51\n",
       "converged:                       True   LL-Null:                       -563.33\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.587e-93\n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                      -0.9606      0.587     -1.636      0.102      -2.111       0.190\n",
       "weak_layers                     0.4327      0.039     11.193      0.000       0.357       0.508\n",
       "surface_hoar                    0.3887      0.039     10.035      0.000       0.313       0.465\n",
       "wind                            0.1204      0.010     11.607      0.000       0.100       0.141\n",
       "no_visitors                    -0.9430      0.114     -8.237      0.000      -1.167      -0.719\n",
       "fresh_thickness                -0.4962      0.069     -7.191      0.000      -0.631      -0.361\n",
       "no_visitors:fresh_thickness     0.1015      0.013      7.835      0.000       0.076       0.127\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_interaction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plot...\n"
     ]
    }
   ],
   "source": [
    "import graphing as gr\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "gr.model_to_surface_plot(model_with_interaction, ['weak_layers', 'wind'], test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fl/p1.png'>\n",
    "\n",
    "<img src='fl/p2.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating plot...\n"
     ]
    }
   ],
   "source": [
    "gr.model_to_surface_plot(model_with_interaction, ['no_visitors', 'fresh_thickness'], test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='fl/p3.png'>\n",
    "\n",
    "<img src='fl/p4.png'>\n",
    "\n",
    "<img src='fl/p5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks quite different to the other! From any side, we can see an s-shape, but these combine in strange ways.\n",
    "\n",
    "We can see that the risk goes up on days with lots of visitors and lots of snow. There is no real risk of avalanche when there's a lot of snow but no visitors, or when there are a lot of visitors but no snow.\n",
    "\n",
    "The fact that it shows high risk when there's no fresh snow and no visitors could be due to rain, which keeps visitors and snow clouds away but results in avalanches of the older snow. To confirm this, we'd need to explore the data in more depth, but we'll stop here for now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
