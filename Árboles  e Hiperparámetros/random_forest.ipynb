{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DayOfWeek  Resolution           X          Y  day_of_year  time_in_hours  \\\n",
      "0          5        True -122.403405  37.775421           29      11.000000   \n",
      "1          5        True -122.403405  37.775421           29      11.000000   \n",
      "2          1        True -122.388856  37.729981          116      14.983333   \n",
      "3          2       False -122.412971  37.785788            5      23.833333   \n",
      "4          5       False -122.419672  37.765050            1       0.500000   \n",
      "\n",
      "   Category_ARSON  Category_ASSAULT  Category_BAD CHECKS  Category_BRIBERY  \\\n",
      "0               0                 0                    0                 0   \n",
      "1               0                 0                    0                 0   \n",
      "2               0                 0                    0                 0   \n",
      "3               0                 0                    0                 0   \n",
      "4               0                 0                    0                 0   \n",
      "\n",
      "   ...  PdDistrict_BAYVIEW  PdDistrict_CENTRAL  PdDistrict_INGLESIDE  \\\n",
      "0  ...                   0                   0                     0   \n",
      "1  ...                   0                   0                     0   \n",
      "2  ...                   1                   0                     0   \n",
      "3  ...                   0                   0                     0   \n",
      "4  ...                   0                   0                     0   \n",
      "\n",
      "   PdDistrict_MISSION  PdDistrict_NORTHERN  PdDistrict_PARK  \\\n",
      "0                   0                    0                0   \n",
      "1                   0                    0                0   \n",
      "2                   0                    0                0   \n",
      "3                   0                    0                0   \n",
      "4                   1                    0                0   \n",
      "\n",
      "   PdDistrict_RICHMOND  PdDistrict_SOUTHERN  PdDistrict_TARAVAL  \\\n",
      "0                    0                    1                   0   \n",
      "1                    0                    1                   0   \n",
      "2                    0                    0                   0   \n",
      "3                    0                    0                   0   \n",
      "4                    0                    0                   0   \n",
      "\n",
      "   PdDistrict_TENDERLOIN  \n",
      "0                      0  \n",
      "1                      0  \n",
      "2                      0  \n",
      "3                      1  \n",
      "4                      0  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "train shape: (135387, 54)\n",
      "test shape: (15044, 54)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Import the data from the .csv file\n",
    "dataset = pandas.read_csv('sf_crime.csv', delimiter=\"\\t\")\n",
    "\n",
    "# Remember to one-hot encode our crime and PdDistrict variables \n",
    "categorical_features = [\"Category\", \"PdDistrict\"]\n",
    "dataset = pandas.get_dummies(dataset, columns=categorical_features, drop_first=False)\n",
    "\n",
    "# Split the dataset in an 90/10 train/test ratio. \n",
    "# Recall that our dataset is very large so we can afford to do this\n",
    "# with only 10% entering the test set\n",
    "train, test = train_test_split(dataset, test_size=0.1, random_state=2, shuffle=True)\n",
    "\n",
    "# Let's have a look at the data and the relationship we are going to model\n",
    "print(dataset.head())\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to go!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Make a utility method that we can re-use throughout this exercise\n",
    "# To easily fit and test out model\n",
    "\n",
    "features = [c for c in dataset.columns if c != \"Resolution\"]\n",
    "\n",
    "def fit_and_test_model(model):\n",
    "    '''\n",
    "    Trains a model and tests it against both train and test sets\n",
    "    '''  \n",
    "    global features\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train[features], train.Resolution)\n",
    "\n",
    "    # Assess its performance\n",
    "    # -- Train\n",
    "    predictions = model.predict(train[features])\n",
    "    train_accuracy = balanced_accuracy_score(train.Resolution, predictions)\n",
    "\n",
    "    # -- Test\n",
    "    predictions = model.predict(test[features])\n",
    "    test_accuracy = balanced_accuracy_score(test.Resolution, predictions)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance:\n",
      "Train accuracy 0.7742407145595661\n",
      "Test accuracy 0.7597105242913844\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "# re-fit our last decision tree to print out its performance\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=10) \n",
    "\n",
    "dt_train_accuracy, dt_test_accuracy = fit_and_test_model(model)\n",
    "\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(\"Train accuracy\", dt_train_accuracy)\n",
    "print(\"Test accuracy\", dt_test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "A random forest is a collection of decision trees that work together to calculate the label for a sample.\n",
    "\n",
    "Trees in a random forest are trained independently, on different partitions of data, and thus develop different biases, but when combined they are less likely to overfit the data.\n",
    "\n",
    "Let's build a very simple forest with two trees and the *default* parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "Train accuracy 0.8842998107846062\n",
      "Test accuracy 0.734378540999183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest model with two trees\n",
    "random_forest = RandomForestClassifier( n_estimators=2,\n",
    "                                        random_state=2,\n",
    "                                        verbose=False)\n",
    "\n",
    "# Train and test the model\n",
    "train_accuracy, test_accuracy = fit_and_test_model(random_forest)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our two-tree forest has done more poorly than the single tree on the test set, though has done a better job on the train set. \n",
    "\n",
    "To some extent this should be expected. Random forests usually work with many more trees. Simply having two allowed it to overfit the training data much better than the original decision tree.\n",
    "\n",
    "## Altering the number of trees\n",
    "\n",
    "Let's then build several forest models, each with a different number of trees, and see how they perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a model with 2 trees...\n",
      "Preparing a model with 5 trees...\n",
      "Preparing a model with 10 trees...\n",
      "Preparing a model with 20 trees...\n",
      "Preparing a model with 50 trees...\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"400\" style=\"\" viewBox=\"0 0 700 400\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"400\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-3874f3\"><g class=\"clips\"><clipPath id=\"clip3874f3xyplot\" class=\"plotclip\"><rect width=\"553\" height=\"324\"/></clipPath><clipPath class=\"axesclip\" id=\"clip3874f3x\"><rect x=\"58\" y=\"0\" width=\"553\" height=\"400\"/></clipPath><clipPath class=\"axesclip\" id=\"clip3874f3y\"><rect x=\"0\" y=\"30\" width=\"700\" height=\"324\"/></clipPath><clipPath class=\"axesclip\" id=\"clip3874f3xy\"><rect x=\"58\" y=\"30\" width=\"553\" height=\"324\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"/><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(150.17000000000002,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(265.38,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(380.58,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(495.79,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,320.59)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,265.52)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,210.44)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,155.36)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,100.28)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,45.21)\" d=\"M58,0h553\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(58,30)\" clip-path=\"url(#clip3874f3xyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter traceb1572d\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,142.66L34.56,46.41L92.17,37.56L207.38,23L553,16.2\" style=\"vector-effect: none; fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace0f5956\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,307.8L34.56,235.63L92.17,235.51L207.38,223.67L553,218.97\" style=\"vector-effect: none; fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M56,355H611\" style=\"fill: none; stroke-width: 2px; stroke: rgb(235, 240, 248); stroke-opacity: 1;\"/><path class=\"ylines-above crisp\" d=\"M57,30V354\" style=\"fill: none; stroke-width: 2px; stroke: rgb(235, 240, 248); stroke-opacity: 1;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" transform=\"translate(150.17000000000002,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">10</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(265.38,0)\">20</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(380.58,0)\">30</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(495.79,0)\">40</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(611,0)\">50</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" transform=\"translate(0,320.59)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0.75</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,265.52)\">0.8</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,210.44)\">0.85</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,155.36)\">0.9</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,100.28)\">0.95</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"53.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,45.21)\">1</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-3874f3\"><g class=\"clips\"/><clipPath id=\"legend3874f3\"><rect width=\"76\" height=\"67\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(622.0600000000001,30)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" width=\"76\" height=\"67\" x=\"0\" y=\"0\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(255, 255, 255); fill-opacity: 1; stroke-width: 0px;\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legend3874f3)\"><text class=\"legendtitletext\" text-anchor=\"start\" x=\"2\" y=\"18.2\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Line</text><g class=\"groups\" transform=\"\"><g class=\"traces\" transform=\"translate(0,32.7)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Train</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"70.234375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g><g class=\"groups\" transform=\"\"><g class=\"traces\" transform=\"translate(0,51.7)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Test</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"70.234375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" x=\"0\" y=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\"/></g><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"350\" y=\"15\" text-anchor=\"middle\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Performance X number of trees</text></g><g class=\"g-xtitle\" transform=\"translate(0,-0.20625000000001137)\"><text class=\"xtitle\" x=\"334.5\" y=\"397.20625\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Numer of trees (n estimators)</text></g><g class=\"g-ytitle\" transform=\"translate(11.4560546875,0)\"><text class=\"ytitle\" transform=\"rotate(-90,2.543750000000003,192)\" x=\"2.543750000000003\" y=\"192\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Accuracy</text></g></g></svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"svg\"\n",
    "\n",
    "# n_estimators states how many trees to put in the model\n",
    "# We will make one model for every entry in this list\n",
    "# and see how well each model performs \n",
    "n_estimators = [2, 5, 10, 20, 50]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    print(\"Preparing a model with\", n_estimator, \"trees...\")\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=n_estimator, \n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies), \n",
    "                    n_estimators,\n",
    "                    label_x=\"Numer of trees (n_estimators)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance X number of trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics look great for the *training* set, but not so much for the *test* set. More trees tended to help both but only up to a point.\n",
    "\n",
    "We might have expected the number of trees to resolve our overfitting problem, but this was not the case! Chances are that the model is simply too complex relative to the data, allowing it to overfit the training set.\n",
    "\n",
    "## Altering the minimum number of samples for split parameter\n",
    "\n",
    "Recall that decision trees have a *root node*, *internal nodes* and *leaf nodes*, and that the first two can be split into newer nodes with subsets of data.\n",
    "\n",
    "If we let our model split and create too many nodes, it can become increasingly complex and start to overfit.\n",
    "\n",
    "One way to limit that complexity is to tell the model that each node needs to have __at least__ a certain number of samples, otherwise it can't split into subnodes. \n",
    "\n",
    "In other words, we can set the model's `min_samples_split` parameter to the least number of samples required so that a node can be split.\n",
    "\n",
    "Our default value for `min_samples_split` is only `2`, so models will quickly become too complex if that parameter is left untouched.\n",
    "\n",
    "We will now use the best performing model above, then try it with different `min_samples_split` values and compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a model with min_samples_split =  2\n",
      "Preparing a model with min_samples_split =  10\n",
      "Preparing a model with min_samples_split =  20\n",
      "Preparing a model with min_samples_split =  50\n",
      "Preparing a model with min_samples_split =  100\n",
      "Preparing a model with min_samples_split =  500\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"400\" style=\"\" viewBox=\"0 0 700 400\"><rect x=\"0\" y=\"0\" width=\"700\" height=\"400\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-a81233\"><g class=\"clips\"><clipPath id=\"clipa81233xyplot\" class=\"plotclip\"><rect width=\"560\" height=\"324\"/></clipPath><clipPath class=\"axesclip\" id=\"clipa81233x\"><rect x=\"51\" y=\"0\" width=\"560\" height=\"400\"/></clipPath><clipPath class=\"axesclip\" id=\"clipa81233y\"><rect x=\"0\" y=\"30\" width=\"700\" height=\"324\"/></clipPath><clipPath class=\"axesclip\" id=\"clipa81233xy\"><rect x=\"51\" y=\"30\" width=\"560\" height=\"324\"/></clipPath></g><g class=\"gradients\"/><g class=\"patterns\"/></defs><g class=\"bglayer\"/><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"minor-gridlayer\"><g class=\"x\"/><g class=\"y\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(161.2,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(273.65,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(386.1,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(498.55,0)\" d=\"M0,30v324\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,337.8)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,279.05)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,220.3)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,161.55)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,102.8)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,44.06)\" d=\"M51,0h560\" style=\"stroke: rgb(235, 240, 248); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(51,30)\" clip-path=\"url(#clipa81233xyplot)\"><g class=\"scatterlayer mlayer\"><g class=\"trace scatter tracebd7d27\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,16.2L9,99.72L20.24,131.5L53.98,155.51L110.2,173.61L560,307.8\" style=\"vector-effect: none; fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g><g class=\"trace scatter trace281340\" style=\"stroke-miterlimit: 2; opacity: 1;\"><g class=\"fills\"/><g class=\"errorbars\"/><g class=\"lines\"><path class=\"js-line\" d=\"M0,191.33L9,191.5L20.24,190.73L53.98,191.96L110.2,196.62L560,307.8\" style=\"vector-effect: none; fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px; opacity: 1;\"/></g><g class=\"points\"/><g class=\"text\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" d=\"M49,355H611\" style=\"fill: none; stroke-width: 2px; stroke: rgb(235, 240, 248); stroke-opacity: 1;\"/><path class=\"ylines-above crisp\" d=\"M50,30V354\" style=\"fill: none; stroke-width: 2px; stroke: rgb(235, 240, 248); stroke-opacity: 1;\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" transform=\"translate(161.2,0)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">100</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(273.65,0)\">200</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(386.1,0)\">300</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(498.55,0)\">400</text></g><g class=\"xtick\"><text text-anchor=\"middle\" x=\"0\" y=\"370.4\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(611,0)\">500</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" transform=\"translate(0,337.8)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\">0.5</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,279.05)\">0.6</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,220.3)\">0.7</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,161.55)\">0.8</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,102.8)\">0.9</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"46.6\" y=\"4.199999999999999\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre; opacity: 1;\" transform=\"translate(0,44.06)\">1</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"smithlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"iciclelayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-a81233\"><g class=\"clips\"/><clipPath id=\"legenda81233\"><rect width=\"76\" height=\"67\" x=\"0\" y=\"0\"/></clipPath></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"legend\" pointer-events=\"all\" transform=\"translate(622.2,30)\"><rect class=\"bg\" shape-rendering=\"crispEdges\" width=\"76\" height=\"67\" x=\"0\" y=\"0\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: rgb(255, 255, 255); fill-opacity: 1; stroke-width: 0px;\"/><g class=\"scrollbox\" transform=\"\" clip-path=\"url(#legenda81233)\"><text class=\"legendtitletext\" text-anchor=\"start\" x=\"2\" y=\"18.2\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Line</text><g class=\"groups\" transform=\"\"><g class=\"traces\" transform=\"translate(0,32.7)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Train</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(99, 110, 250); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"70.234375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g><g class=\"groups\" transform=\"\"><g class=\"traces\" transform=\"translate(0,51.7)\" style=\"opacity: 1;\"><text class=\"legendtext\" text-anchor=\"start\" x=\"40\" y=\"4.680000000000001\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">Test</text><g class=\"layers\" style=\"opacity: 1;\"><g class=\"legendfill\"/><g class=\"legendlines\"><path class=\"js-line\" d=\"M5,0h30\" style=\"fill: none; stroke: rgb(239, 85, 59); stroke-opacity: 1; stroke-width: 2px;\"/></g><g class=\"legendsymbols\"><g class=\"legendpoints\"/></g></g><rect class=\"legendtoggle\" x=\"0\" y=\"-9.5\" width=\"70.234375\" height=\"19\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0;\"/></g></g></g><rect class=\"scrollbar\" rx=\"20\" ry=\"3\" width=\"0\" height=\"0\" x=\"0\" y=\"0\" style=\"fill: rgb(128, 139, 164); fill-opacity: 1;\"/></g><g class=\"g-gtitle\"><text class=\"gtitle\" x=\"350\" y=\"15\" text-anchor=\"middle\" dy=\"0em\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 17px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Performance</text></g><g class=\"g-xtitle\" transform=\"translate(0,-0.20625000000001137)\"><text class=\"xtitle\" x=\"331\" y=\"397.20625\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Minimum samples split (min samples split)</text></g><g class=\"g-ytitle\" transform=\"translate(10.8310546875,0)\"><text class=\"ytitle\" transform=\"rotate(-90,3.168750000000003,192)\" x=\"3.168750000000003\" y=\"192\" text-anchor=\"middle\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 14px; fill: rgb(42, 63, 95); opacity: 1; font-weight: normal; white-space: pre;\">Accuracy</text></g></g></svg>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shrink the training set temporarily to explore this\n",
    "# setting with a more normal sample size\n",
    "full_trainset = train\n",
    "train = full_trainset[:1000] # limit to 1000 samples\n",
    "\n",
    "min_samples_split = [2, 10, 20, 50, 100, 500]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for min_samples in min_samples_split:\n",
    "    print(\"Preparing a model with min_samples_split = \", min_samples)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=20,\n",
    "                                min_samples_split=min_samples,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies), \n",
    "                    min_samples_split,\n",
    "                    label_x=\"Minimum samples split (min_samples_split)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance\", show=True)\n",
    "\n",
    "# Rol back the trainset to the full set\n",
    "train = full_trainset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, small restrictions on the model's complexity - by limiting its ability to split nodes - reduce the gap between training and test performance. If this is subtle, it does so without damaging test performance at all.\n",
    "\n",
    "By limiting the model complexity we address `overfitting`, improving its ability to generalize and make accurate predictions on *unseen* data.\n",
    "\n",
    "Notice that using `min_samples_split=20` gave us the best result for the *test* set, and that higher values worsened outcomes.\n",
    "\n",
    "## Altering the model depth\n",
    "\n",
    "A related method to limit the trees is restricting `max_depth`. This is equivalent to `max_depth` we used for our decision tree, earlier. Its default value is `None`, which means nodes can be expanded until all leaves are *pure* (all samples in it have the same label) or have less samples than the value set for `min_samples_split`.\n",
    "\n",
    "Whether `max_depth`, or `min_samples_split` is more appropriate depends on the nature of your dataset, including its size. Usually we need to experiment to find the best settings. Let's investigate `max_depth` as though we only had 500 crime samples available for our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a model with max_depth =  2\n",
      "Preparing a model with max_depth =  4\n",
      "Preparing a model with max_depth =  6\n",
      "Preparing a model with max_depth =  8\n",
      "Preparing a model with max_depth =  10\n",
      "Preparing a model with max_depth =  15\n",
      "Preparing a model with max_depth =  20\n",
      "Preparing a model with max_depth =  50\n",
      "Preparing a model with max_depth =  100\n"
     ]
    }
   ],
   "source": [
    "# Shrink the training set temporarily to explore this\n",
    "# setting with a more normal sample size\n",
    "full_trainset = train\n",
    "train = full_trainset[:500] # limit to 500 samples\n",
    "\n",
    "max_depths = [2, 4, 6, 8, 10, 15, 20, 50, 100]\n",
    "\n",
    "# Train our models and report their performance\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    print(\"Preparing a model with max_depth = \", max_depth)\n",
    "\n",
    "    # Prepare the model \n",
    "    rf = RandomForestClassifier(n_estimators=20,\n",
    "                                max_depth=max_depth,\n",
    "                                random_state=2, \n",
    "                                verbose=False)\n",
    "    \n",
    "    # Train and test the result\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "    # Save the results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "graphing.line_2D(dict(Train=train_accuracies, Test=test_accuracies),\n",
    "                    max_depths,\n",
    "                    label_x=\"Maximum depth (max_depths)\",\n",
    "                    label_y=\"Accuracy\",\n",
    "                    title=\"Performance\")\n",
    "\n",
    "# Rol back the trainset to the full set\n",
    "train = full_trainset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above tells us that our model actually __benefits__ from a higher value for `max_depth`, up to the limit of `15`.\n",
    "\n",
    "Increasing depth beyond this point begins to harm test performence, as it constrains the model too much for it to generalize.\n",
    "\n",
    "As usual, it is important to evaluate different values when setting model parameters and defining its architecture.\n",
    "\n",
    "## An optimised model\n",
    "\n",
    "Properly optimizing a model on a dataset this large can take many hours - more than you need to commit to this exercise just to learn. If you would like to run a model that has already been optimized for the full dataset, you can run the code below, and compare its performance to everything we have seen so far.\n",
    "\n",
    "This is optional - just note that the model may take 1 - 2 minutes to train due to its size and the sheer volume of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model. This may take 1 - 2 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train sensitivity</th>\n",
       "      <th>Test sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.774241</td>\n",
       "      <td>0.759711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final random forest</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.816087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train sensitivity  Test sensitivity\n",
       "0        Decision tree           0.774241          0.759711\n",
       "1  Final random forest           0.999657          0.816087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the model \n",
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                            max_depth=128,\n",
    "                            max_features=25,\n",
    "                            min_samples_split=2,\n",
    "                            random_state=2, \n",
    "                            verbose=False)\n",
    "\n",
    "# Train and test the result\n",
    "print(\"Training model. This may take 1 - 2 minutes\")\n",
    "train_accuracy, test_accuracy = fit_and_test_model(rf)\n",
    "\n",
    "# Print out results, compared to the decision tree\n",
    "data = {\"Model\": [\"Decision tree\",\"Final random forest\"],\n",
    "        \"Train sensitivity\": [dt_train_accuracy, train_accuracy],\n",
    "        \"Test sensitivity\": [dt_test_accuracy, test_accuracy]\n",
    "        }\n",
    "\n",
    "pandas.DataFrame(data, columns = [\"Model\", \"Train sensitivity\", \"Test sensitivity\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, fine tuning the model's parameters resulted in a significant improvement in the test set results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
